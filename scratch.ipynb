{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46",
   "display_name": "Python 3.8.5  ('nlpenv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import gensim\n",
    "from multiprocessing import Process, Queue\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "def compute_coherence_values(corpus, dictionary, k, a='symmetric', b=None, coherence='u_mass', texts=None):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b,\n",
    "                                           workers=10)\n",
    "    \n",
    "    if coherence == 'u_mass':\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, coherence=coherence, processes=4)\n",
    "    else:\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, coherence=coherence, processes=4)\n",
    "\n",
    "    # print('coherence: ', coherence_model_lda.get_coherence())\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return SnowballStemmer('english').stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def get_preprocessed(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "\n",
    "def wrapped_load_tweets(pqueue, filenames, preprocess=False):\n",
    "    all_tweets = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as f:\n",
    "            # add commas between tweets to correct json syntax\n",
    "            data = json.loads('['+f.read().replace('}{','},{')+']')\n",
    "        # remove retweets\n",
    "        tweets = [tweet for tweet in data if 'retweeted_status' not in tweet]\n",
    "        # keep english language tweets only\n",
    "        tweets = [tweet for tweet in tweets if tweet['lang'] == 'en']\n",
    "\n",
    "        # take tweet text  or full_text if the tweet has that attribute\n",
    "        if preprocess:\n",
    "            ttexts = [ get_preprocessed(tweet['extended_tweet']['full_text']) if 'full_text' in tweet else get_preprocessed(tweet['text']) for tweet in tweets]\n",
    "        else:\n",
    "            ttexts = [ tweet['extended_tweet']['full_text'] if 'full_text' in tweet else tweet['text'] for tweet in tweets]\n",
    "\n",
    "\n",
    "        all_tweets = all_tweets + ttexts\n",
    "\n",
    "\n",
    "    if pqueue:\n",
    "        pqueue.put(all_tweets[:50])\n",
    "    return all_tweets\n",
    "\n",
    "def partition(seq, num):\n",
    "    # if num == 1:\n",
    "    #     return [seq]\n",
    "\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_tweets(filenames, preprocess=False, workers=1):\n",
    "    assert type(filenames) == list\n",
    "    partitioned_filenames = partition(filenames, workers)\n",
    "    print(partitioned_filenames)\n",
    "    pqueue = Queue()\n",
    "    # make wprocesses\n",
    "    procs = [ Process(target=wrapped_load_tweets, args=(pqueue, filenames, preprocess)) for filenames in partitioned_filenames ]\n",
    "    # start processes\n",
    "    for proc in procs:\n",
    "        proc.start()\n",
    "    # get results from all procs\n",
    "    dumped = []\n",
    "    print('returning')\n",
    "    while not pqueue.empty():\n",
    "        dumped.append(pqueue.get())\n",
    "\n",
    "    # wait until all processes have finished\n",
    "    print('joining')\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "    pqueue.close()\n",
    "    pqueue.join_thread()\n",
    "\n",
    "    # return flattened list of results\n",
    "    return [tweet for tweets in dumped for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['data/unzipped/twitter-coronavirus-A-2020-05-01-04-48-29-6c51e071-3229-4b36-9f2d-5c9dc05b78f2']]\n",
      "joining\n",
      "returning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filenames = ['data/unzipped/' + name for name in os.listdir('data/unzipped')]\n",
    "\n",
    "data = load_tweets([filenames[0]])\n",
    "# filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Due to the coronavirus outbreak, April 2020 was the first April without a school shooting in the U.S. since 2001.',\n",
       " 'Nursing Home On Queens-LI Border Reports 53 Coronavirus Deaths',\n",
       " '\"Coronavirus Live Updates: In China, Loosened Restrictions Lead to Travel Rush\" by Unknown Author via NYT New Yorkâ€¦ https://t.co/f0VIBgnRV3',\n",
       " \"China's Banks are leveraged, low capitalized and are facing mounting credit losses.\\n@chigrl @SCMPNewsâ€¦ https://t.co/cpFofBSDnM\",\n",
       " \"They won't have to, idiot. Take a guess how it ends. Guess. Fucking idiot. https://t.co/xsoo0GksSp\",\n",
       " 'Yes this is the correct news \\n Pm of Russia suffering from corona',\n",
       " 'Hey @realdonaldtrump  @potus the novel coronavirus did NOT originate in a laboratory in Wuhan!  You do not understaâ€¦ https://t.co/wnXDwlArh4',\n",
       " 'Cleaner Air Because of Coronavirus Lockdowns Is Saving Thousands of Lives https://t.co/Pz8mSHr7OR via @vice',\n",
       " '@HuXijin_GT The US, and our citizens, stand with Australia against Communist China. Hu, you arrogant prick, your goâ€¦ https://t.co/z1y3xKPm2p',\n",
       " 'BBC News - Coronavirus: Trump seems to undercut US spies on virus origins https://t.co/her6An0l8p',\n",
       " '@narendramodi @MIB_India @rsprasad @AmitShahOffice @AmitShah ministry of I&amp;Bmust ban this onlineâ€¦ https://t.co/mqrrPI1s7X',\n",
       " 'For Some Trump Voters, Coronavirus Was The Last Straw | Time https://t.co/bwXnaOhrsN',\n",
       " '.\\nTrump Hiding Coronavirus Numbers ?\\nOne Conclusion ONLY: The Numbers MUST BE VERY TERRIBLE.\\n\\nTrump Wants You to Maâ€¦ https://t.co/iupxbxqWLg',\n",
       " '@andersoncooper @thantmyintu Imagine if Wyatt was aborted! 2 precious 2 abort right? Well what about the other 1 miâ€¦ https://t.co/JUH19xYpYH',\n",
       " 'Apple and Googleâ€™s smartphone coronavirus contact-tracing program to hit enlisting snag â€“\\xa0NEWPAPER24â€¦ https://t.co/RikGeDGUqL',\n",
       " 'Can Lava Kill The Coronavirus? https://t.co/MkJYEOQkqL',\n",
       " '@therealarekn https://t.co/8LfmsgPUTl AND #AngelaMerkel is a #SCIENTIST helping HER Country #Germany combatâ€¦ https://t.co/JYm6vNrVZo',\n",
       " 'The president said he had \"evidence\" of a coronavirus-related conspiracy theory. https://t.co/qsIcxFtumg',\n",
       " 'Bauchi governor authorises use of chloroquine for coronavirus\\xa0treatment https://t.co/9He5tZaXQF https://t.co/hC2SYklnUq',\n",
       " \"Why coronavirus is making Putin's situation increasingly precarious https://t.co/QfyrbmSrxA\",\n",
       " \"Coronavirus stars: BBC sports commentator Andrew Cotter's dogs Olive and Mabel go viral | Dogs | The Guardian https://t.co/jXyjC2okTD\",\n",
       " '#CoronavirusOutbreak | With 583 fresh cases recorded in last 24 hours, the total number of coronavirus patients inâ€¦ https://t.co/1k9M3hSFNu',\n",
       " \"'We Will Not Give Up': Marking 3 Months Since Coronavirus Became A Global Emergency https://t.co/TtHDsQ6YoG\",\n",
       " 'Hey Oregonian, these thousands are what % of 4 million citizens? How about some perspective? Crappy headline',\n",
       " 'Smh the state took long enough',\n",
       " 'Why not ask China directly???\\n\\nhttps://t.co/gyLbEp9ds9',\n",
       " 'Coronavirus in Illinois updates: Hereâ€™s whatâ€™s happening Thursday Get You Mask and Covers Here!â€¦ https://t.co/H24nVVFX0d',\n",
       " 'China Selling Faulty &amp; Defective Medical Supplies To World. \\n https://t.co/px9B6D8LY2',\n",
       " \"@ilyseh Humane trap and release outdoors might be a really good idea. You don't want to avoid Coronavirus only to end up with Hantavirus.\",\n",
       " 'Person of Interest might be happening, folks. \\nAnd yeah, also Watch Dogs, too.\\n\\nhttps://t.co/4Z07xObyi8',\n",
       " '(28) Security State Using Coronavirus To Implement Orwellian Nightmare - YouTube https://t.co/oh4l27lxgE',\n",
       " 'Coronavirus: WhakatÅ« is the coolest little town around | https://t.co/e8Z0Z0u2Gn https://t.co/WA7zpb8hUn',\n",
       " 'Watch this coronavirus â€œpull a Spanish fluâ€ on the world â€” and come back around in a mutated form *far more lethal*â€¦ https://t.co/pJTUBEqP6k',\n",
       " \"@realDonaldTrump just had one too many Clorox martiniâ€™s.   \\n\\nTrump says he's seen evidence suggesting coronavirus eâ€¦ https://t.co/4ouGRE8hsq\",\n",
       " '@BrockStetson1 @cooperhefner Thatâ€™s right, pick on a typo and make your point with profanity.\\n\\nTell me what need waâ€¦ https://t.co/sKuZ3uBSPs',\n",
       " '@TinkTink384 I wish had that choice.  My job said we resuming regular work schedule next week. #coronavirus ðŸ˜’',\n",
       " '@CNNPolitics Anyone with half a brain has seen the evidence.\\n\\nThe lab is less than a block away from the Market. Thâ€¦ https://t.co/8GNmMG2Aqb',\n",
       " 'absolutely cannot stop thinking abt that tumblr post from last year that predicted coronavirus',\n",
       " 'The parent in this photo is me...!!',\n",
       " 'Will this ssme hospital in 2013 misdiganosed my stroke, assaut by sezurity guard Dominic,   no apology  deleted vidâ€¦ https://t.co/9jnTOLdACz',\n",
       " 'What. The. Actual. Fuck. ðŸ¤£ðŸ¤£ðŸ¤£',\n",
       " 'The first destination for you after coronavirus??',\n",
       " 'We are close to 40 days in county lockdown.\\n\\nThe CURVE is yet to take a slight BEND â—ï¸\\n\\nIn which one way we won theâ€¦ https://t.co/zmCtfocfia',\n",
       " 'Who believes him? This is very easy to check, if you know anything about science. And you will stand there embarrasâ€¦ https://t.co/oxnMEx2qIo',\n",
       " 'This idiot right here. Maggot.',\n",
       " \"Australia earns an 'early mark' on easing coronavirus restrictions  https://t.co/kQypPats71\",\n",
       " '@thetimes On 28 April, Govt said it will now publish daily numbers for #COVID19 deaths outside as well as inside hoâ€¦ https://t.co/qMIxZ2qkAF',\n",
       " 'Whistleblower complaint set to lift lid on Trump pressure to push untried drug https://t.co/Bxut2tyRq5',\n",
       " '@realDonaldTrump  How does the greatest country in the world get outshined by every other country taking better carâ€¦ https://t.co/iSj7fq0Tsh',\n",
       " 'California official calls for reopening so coronavirus can kill off the old and the weak: â€˜It would also free up hoâ€¦ https://t.co/vzEqMZIEIm']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}