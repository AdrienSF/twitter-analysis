{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46",
   "display_name": "Python 3.8.5  ('nlpenv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n",
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/matplotlib_inline/config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from helpers import lemmatize_stemming, get_preprocessed, compute_coherence_values\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "filenames = !ls data/unzipped\n",
    "filenames = [ 'data/unzipped/'+filename for filename in filenames ]\n",
    "\n",
    "import random\n",
    "# indeces = random.sample(range(len(filenames)), 50)\n",
    "indeces = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_tweets\n",
    "\n",
    "documents = load_tweets(np.array(filenames)[indeces])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "processed_docs = [ get_preprocessed(doc, stemmer, lemmatizer) for doc in documents ]\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "tfidf = gensim.models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Topic: 0 \n",
      "Words: 0.009*\"protect\" + 0.009*\"lockdown\" + 0.007*\"stay\" + 0.007*\"help\" + 0.006*\"inform\" + 0.006*\"coronavirus\" + 0.006*\"cover\" + 0.005*\"doctor\" + 0.005*\"week\" + 0.005*\"american\"\n",
      "Topic: 1 \n",
      "Words: 0.010*\"state\" + 0.009*\"case\" + 0.008*\"true\" + 0.008*\"coronavirus\" + 0.008*\"china\" + 0.007*\"realdonaldtrump\" + 0.007*\"death\" + 0.007*\"updat\" + 0.006*\"stupid\" + 0.006*\"leader\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"intellig\" + 0.007*\"take\" + 0.007*\"theori\" + 0.006*\"manmad\" + 0.005*\"coronavirus\" + 0.005*\"vaccin\" + 0.005*\"conspiraci\" + 0.005*\"debunk\" + 0.004*\"spread\" + 0.004*\"gonna\"\n",
      "Topic: 3 \n",
      "Words: 0.010*\"thank\" + 0.007*\"coronavirus\" + 0.007*\"love\" + 0.007*\"long\" + 0.007*\"chang\" + 0.007*\"tell\" + 0.006*\"natur\" + 0.006*\"go\" + 0.006*\"patient\" + 0.006*\"stori\"\n",
      "Topic: 4 \n",
      "Words: 0.010*\"lie\" + 0.009*\"coronavirus\" + 0.007*\"trump\" + 0.007*\"million\" + 0.007*\"dead\" + 0.007*\"issu\" + 0.006*\"lose\" + 0.006*\"worldwid\" + 0.005*\"social\" + 0.005*\"report\"\n",
      "Topic: 5 \n",
      "Words: 0.022*\"trump\" + 0.014*\"evid\" + 0.010*\"see\" + 0.009*\"chines\" + 0.008*\"presid\" + 0.008*\"origin\" + 0.008*\"coronavirus\" + 0.007*\"claim\" + 0.007*\"obama\" + 0.006*\"contradict\"\n",
      "Topic: 6 \n",
      "Words: 0.008*\"worker\" + 0.008*\"care\" + 0.007*\"plant\" + 0.006*\"meat\" + 0.006*\"indiana\" + 0.005*\"near\" + 0.005*\"music\" + 0.005*\"economi\" + 0.005*\"coronavirus\" + 0.005*\"covid\"\n",
      "Topic: 7 \n",
      "Words: 0.009*\"fuck\" + 0.009*\"right\" + 0.009*\"michigan\" + 0.008*\"stop\" + 0.008*\"counti\" + 0.008*\"coronavirus\" + 0.008*\"know\" + 0.007*\"good\" + 0.007*\"arm\" + 0.007*\"protest\"\n",
      "Topic: 8 \n",
      "Words: 0.013*\"death\" + 0.012*\"test\" + 0.009*\"coronavirus\" + 0.008*\"case\" + 0.007*\"need\" + 0.007*\"posit\" + 0.006*\"fact\" + 0.005*\"open\" + 0.005*\"toll\" + 0.005*\"countri\"\n",
      "Topic: 9 \n",
      "Words: 0.012*\"time\" + 0.010*\"case\" + 0.008*\"total\" + 0.008*\"virus\" + 0.008*\"coronavirus\" + 0.008*\"confirm\" + 0.006*\"treatment\" + 0.006*\"urg\" + 0.006*\"global\" + 0.005*\"white\"\n",
      "Topic: 10 \n",
      "Words: 0.007*\"liter\" + 0.007*\"research\" + 0.007*\"support\" + 0.006*\"continu\" + 0.005*\"peopl\" + 0.005*\"announc\" + 0.005*\"donat\" + 0.005*\"coronavirus\" + 0.004*\"covid\" + 0.004*\"share\"\n",
      "Topic: 11 \n",
      "Words: 0.014*\"covid\" + 0.012*\"coronavirus\" + 0.010*\"like\" + 0.009*\"pandem\" + 0.009*\"think\" + 0.008*\"free\" + 0.008*\"cancel\" + 0.007*\"world\" + 0.007*\"money\" + 0.007*\"respons\"\n",
      "Topic: 12 \n",
      "Words: 0.010*\"look\" + 0.007*\"quarantin\" + 0.006*\"corona\" + 0.006*\"nytim\" + 0.005*\"tri\" + 0.005*\"number\" + 0.005*\"conserv\" + 0.005*\"coronavirus\" + 0.004*\"interest\" + 0.004*\"walk\"\n",
      "Topic: 13 \n",
      "Words: 0.021*\"coronavirus\" + 0.007*\"public\" + 0.006*\"mask\" + 0.006*\"year\" + 0.006*\"news\" + 0.006*\"want\" + 0.006*\"media\" + 0.005*\"latest\" + 0.005*\"infect\" + 0.005*\"talk\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=14, id2word=dictionary, passes=10, workers=4, alpha=0.01, eta=.91)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('trained_lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus_tfidf, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}