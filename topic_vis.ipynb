{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46",
   "display_name": "Python 3.8.5  ('nlpenv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "de8d688998391b4e340423aec176e4bbb9afb78f2320e3ca59b2d8556c4a2b46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n",
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/matplotlib_inline/config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from helpers import lemmatize_stemming, get_preprocessed, compute_coherence_values\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "filenames = !ls data/unzipped\n",
    "filenames = [ 'data/unzipped/'+filename for filename in filenames ]\n",
    "\n",
    "import random\n",
    "# indeces = random.sample(range(len(filenames)), 50)\n",
    "indeces = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_tweets\n",
    "\n",
    "documents = load_tweets(np.array(filenames)[indeces])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "processed_docs = [ get_preprocessed(doc) for doc in documents ]\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "tfidf = gensim.models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/adrien/twitter-analysis/nlpenv/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Topic: 0 \n",
      "Words: 0.012*\"lie\" + 0.010*\"tell\" + 0.010*\"trump\" + 0.010*\"time\" + 0.009*\"good\" + 0.007*\"respons\" + 0.007*\"read\" + 0.007*\"realdonaldtrump\" + 0.007*\"coronavirus\" + 0.005*\"piec\"\n",
      "Topic: 1 \n",
      "Words: 0.014*\"think\" + 0.008*\"virus\" + 0.007*\"coronavirus\" + 0.006*\"pandem\" + 0.006*\"news\" + 0.006*\"fake\" + 0.006*\"johnson\" + 0.006*\"drop\" + 0.005*\"treatment\" + 0.005*\"peak\"\n",
      "Topic: 2 \n",
      "Words: 0.019*\"trump\" + 0.016*\"evid\" + 0.013*\"see\" + 0.010*\"coronavirus\" + 0.010*\"wuhan\" + 0.009*\"china\" + 0.009*\"say\" + 0.008*\"chines\" + 0.008*\"origin\" + 0.007*\"suggest\"\n",
      "Topic: 3 \n",
      "Words: 0.020*\"covid\" + 0.010*\"coronavirus\" + 0.007*\"thank\" + 0.006*\"surg\" + 0.006*\"quarantin\" + 0.006*\"natur\" + 0.006*\"corona\" + 0.006*\"onlin\" + 0.005*\"virus\" + 0.005*\"white\"\n",
      "Topic: 4 \n",
      "Words: 0.010*\"protest\" + 0.009*\"care\" + 0.009*\"worker\" + 0.007*\"michigan\" + 0.006*\"arm\" + 0.006*\"coronavirus\" + 0.006*\"health\" + 0.006*\"minist\" + 0.006*\"get\" + 0.005*\"capitol\"\n",
      "Topic: 5 \n",
      "Words: 0.018*\"case\" + 0.014*\"death\" + 0.010*\"coronavirus\" + 0.009*\"world\" + 0.008*\"covid\" + 0.007*\"stop\" + 0.007*\"countri\" + 0.007*\"liter\" + 0.006*\"intellig\" + 0.006*\"india\"\n",
      "Topic: 6 \n",
      "Words: 0.010*\"mask\" + 0.008*\"face\" + 0.006*\"open\" + 0.006*\"compani\" + 0.006*\"wear\" + 0.006*\"issu\" + 0.006*\"coronavirus\" + 0.006*\"vote\" + 0.005*\"place\" + 0.005*\"store\"\n",
      "Topic: 7 \n",
      "Words: 0.011*\"test\" + 0.009*\"obama\" + 0.009*\"die\" + 0.008*\"coronavirus\" + 0.007*\"video\" + 0.007*\"lockdown\" + 0.006*\"nurs\" + 0.005*\"terrorist\" + 0.005*\"symptom\" + 0.005*\"trump\"\n",
      "Topic: 8 \n",
      "Words: 0.007*\"crisi\" + 0.007*\"hope\" + 0.006*\"inform\" + 0.006*\"immun\" + 0.006*\"turn\" + 0.006*\"coronavirus\" + 0.006*\"come\" + 0.006*\"like\" + 0.006*\"post\" + 0.005*\"covid\"\n",
      "Topic: 9 \n",
      "Words: 0.022*\"coronavirus\" + 0.007*\"best\" + 0.007*\"recoveri\" + 0.007*\"worldwid\" + 0.006*\"report\" + 0.006*\"love\" + 0.006*\"stay\" + 0.005*\"million\" + 0.005*\"vitamin\" + 0.005*\"stori\"\n",
      "Topic: 10 \n",
      "Words: 0.011*\"look\" + 0.011*\"right\" + 0.009*\"fuck\" + 0.007*\"like\" + 0.006*\"support\" + 0.006*\"sign\" + 0.006*\"coronavirus\" + 0.005*\"feel\" + 0.005*\"normal\" + 0.005*\"social\"\n",
      "Topic: 11 \n",
      "Words: 0.016*\"vaccin\" + 0.008*\"children\" + 0.007*\"fee\" + 0.007*\"long\" + 0.007*\"hungri\" + 0.007*\"pandem\" + 0.006*\"lose\" + 0.006*\"coronavirus\" + 0.006*\"know\" + 0.005*\"hour\"\n",
      "Topic: 12 \n",
      "Words: 0.011*\"need\" + 0.011*\"go\" + 0.007*\"want\" + 0.007*\"corrupt\" + 0.007*\"week\" + 0.006*\"nytim\" + 0.006*\"like\" + 0.006*\"tri\" + 0.006*\"project\" + 0.005*\"blame\"\n",
      "Topic: 13 \n",
      "Words: 0.008*\"live\" + 0.008*\"test\" + 0.008*\"posit\" + 0.007*\"worker\" + 0.007*\"plant\" + 0.007*\"coronavirus\" + 0.006*\"question\" + 0.006*\"medic\" + 0.005*\"close\" + 0.005*\"surviv\"\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus_tfidf, num_topics=14, id2word=dictionary, passes=10, workers=4, alpha=0.01, eta=.91)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('trained_lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus_tfidf, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}